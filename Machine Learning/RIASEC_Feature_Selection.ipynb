{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Feature Selection.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjiSiwi/arunika-temuin/blob/master/Machine%20Learning/RIASEC_Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hpqGP-SdD8e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULhUzNhjdD8y"
      },
      "source": [
        "dataset = pd.read_excel('preprocessed_RIASEC.xlsx', engine = 'openpyxl')\n",
        "dataset.head(n = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm_nJmORdD83"
      },
      "source": [
        "# dataset.drop(columns = ['Unnamed: 0']) # Uncomment this line if filename == 'preprocessed_RIASEC_Class3.xlsx'\n",
        "data_cols = list(dataset.columns)\n",
        "data_cols.remove('major')\n",
        "data = dataset[data_cols].values\n",
        "labels = dataset['major'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f1hHkYgdD85"
      },
      "source": [
        "labels = labels.reshape((1, labels.shape[0]))\n",
        "transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(sparse = False), [0])], \n",
        "                                remainder = 'passthrough')\n",
        "labels = transformer.fit_transform(labels.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy6Kj1PidD88"
      },
      "source": [
        "def create_model(input_shape, learning_rate = 1e-4, dropout_rate = 0.2, optimizer = None):\n",
        "    \"\"\"\n",
        "    Create a three layers DNN model with 2 dropout layers for regularization. \n",
        "    \n",
        "    Keyword Argument:\n",
        "    input_shape -- a tuple defining the input_shape of the first layer. The value equals to the number of\n",
        "                   features used.\n",
        "    learning_rate -- defines the learning rate to be used for the default Adam optimizer. Default\n",
        "                     value is 1e-4.\n",
        "    dropout_rate -- defines the percentage of total weights to be dropped. Default value is 0.2, \n",
        "                    meaning 20% of total weights are zeroed.\n",
        "    optimizer -- if None, Adam will be used as default optimizer. Pass a tf.keras.optimizers method\n",
        "                 to use another optimizer.\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(units = 256, input_shape = input_shape, activation = 'relu'),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(units = 128, activation = 'relu'),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(units = 5, activation = 'softmax')\n",
        "    ])\n",
        "    if not optimizer:\n",
        "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "                      loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    else:\n",
        "        model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhv2eAPwdD9A"
      },
      "source": [
        "def predict_assess(model, validation_data, validation_label):\n",
        "    \"\"\"\n",
        "    Make predictions based on an array of data and assess the prediction using \n",
        "    accuracy, precision, and recall.\n",
        "    \n",
        "    Keyword Argument:\n",
        "    model -- the model for making predictions.\n",
        "    \n",
        "    validation_data -- an array of data for making predictions.\n",
        "    \n",
        "    validation_label -- an array of labels of the data in validation_data.\n",
        "    \"\"\"\n",
        "    predictions = model.predict(validation_data)\n",
        "    predictions = np.array([np.argmax(prediction) for prediction in predictions])\n",
        "    actuals = np.array([np.argmax(actual) for actual in validation_label])\n",
        "    accuracy = accuracy_score(predictions, actuals)\n",
        "    precision = precision_score(predictions, actuals, average = 'weighted')\n",
        "    recall = recall_score(predictions, actuals, average = 'weighted')\n",
        "    return accuracy, precision, recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDw2s7ijdD9D"
      },
      "source": [
        "def training_report(accuracy, precision, recall, num_features = None):\n",
        "    \"\"\"\n",
        "    Print a training report based on model's performance. \n",
        "    \n",
        "    Keyword Argument:\n",
        "    accuracy -- the accuracy score of the model.\n",
        "    \n",
        "    precision -- precision score.\n",
        "    \n",
        "    recall -- recall score.\n",
        "    \n",
        "    num_features -- a scalar value defining the number of features used during training.\n",
        "                    If None, all features are assumed to be in use.\n",
        "    \"\"\"\n",
        "    if not num_features:\n",
        "        print('Accuracy, Precision, and Recall for all features')\n",
        "    else:\n",
        "        print('Accuracy, Precision, and Recall for {} features'.format(num_features))\n",
        "    print('Accuracy: {}'.format(acc))\n",
        "    print('Precision: {}'.format(prec))\n",
        "    print('Recall: {}'.format(rec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESTKRVvSdD9H"
      },
      "source": [
        "training_history = {'num_features': [], 'acc': [], 'prec': [], 'rec': []}\n",
        "def add_to_history(hist_dict, n_features, acc, prec, rec):\n",
        "    \"\"\"\n",
        "    Add model's performance result to hist_dict dictionary containing 'num_features',\n",
        "    'acc', 'prec', and 'rec' keys. The value of all keys are in lists.\n",
        "    \n",
        "    Keyword Argument:\n",
        "    hist_dict -- the dictionary where training performance will be saved. Must contain\n",
        "                 'num_features', 'acc', 'prec', and 'rec' keys in which all of them must be\n",
        "                 lists.\n",
        "    \n",
        "    n_features -- number of features used during training. The value will be added to \n",
        "                  'num_features'.\n",
        "                  \n",
        "    acc -- the obtained accuracy of a model.\n",
        "    \n",
        "    prec -- precision score of a model.\n",
        "    \n",
        "    rec -- recall score.\n",
        "    \"\"\"\n",
        "    hist_dict['num_features'].append(n_features)\n",
        "    hist_dict['acc'].append(acc)\n",
        "    hist_dict['prec'].append(prec)\n",
        "    hist_dict['rec'].append(rec)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hPZcdmFdD9O"
      },
      "source": [
        "data_train, data_test, label_train, label_test = train_test_split(data, labels, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IVmhMmYwdD9T"
      },
      "source": [
        "model = create_model(input_shape = (len(dataset.columns) - 1, ), \n",
        "                     optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-3))\n",
        "history = model.fit(data_train, label_train, batch_size = 32, epochs = 280, validation_data = (data_test, label_test))\n",
        "acc, prec, rec = predict_assess(model, data_test, label_test)\n",
        "training_report(acc, prec, rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvWgr7x_dD9V"
      },
      "source": [
        "k_fold = KFold(n_splits = 5)\n",
        "for train_index, test_index in k_fold.split(data):\n",
        "    data_train, data_test = data[train_index], data[test_index]\n",
        "    label_train, label_test = labels[train_index], labels[test_index]\n",
        "    model = create_model(input_shape = (len(dataset.columns) - 1, ))\n",
        "    history = model.fit(data_train, label_train, batch_size = 32, epochs = 50)\n",
        "    acc, prec, rec = predict_assess(model, data_test, label_test)\n",
        "    training_report(acc, prec, rec)\n",
        "    add_to_history(training_history, len(dataset.columns), acc, prec, rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDlP3FDydD9X"
      },
      "source": [
        "classifier = RandomForestClassifier(n_estimators = 1500, random_state = 42, n_jobs = -1)\n",
        "classifier.fit(data_train, label_train)\n",
        "feat_labels = dataset.columns[:-1]\n",
        "importances = classifier.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX8udOgYdD9Z"
      },
      "source": [
        "plt.figure(figsize = (12, 4))\n",
        "plt.title('Feature Importances')\n",
        "plt.bar(range(data_train.shape[1]), importances[indices], color='lightblue', align='center')\n",
        "plt.xticks(range(data_train.shape[1]), feat_labels[indices], rotation=90)\n",
        "plt.xlim([-1, data_train.shape[1]])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G21vYS4JdD9a"
      },
      "source": [
        "threshold = 40\n",
        "total_features = len(feat_labels) - 1\n",
        "for num_features in range(total_features, threshold, -1):\n",
        "    new_dataset = dataset.drop(columns = feat_labels[indices[num_features:]])\n",
        "    new_data = new_dataset[feat_labels[indices[:num_features]]].values\n",
        "    new_labels = new_dataset['major'].values\n",
        "    new_labels = new_labels.reshape((1, new_labels.shape[0]))\n",
        "    new_labels = transformer.fit_transform(new_labels.T)\n",
        "    for train_index, test_index in k_fold.split(new_data):\n",
        "        data_train, data_test = new_data[train_index], new_data[test_index]\n",
        "        label_train, label_test = labels[train_index], labels[test_index]\n",
        "        model = create_model(input_shape = (num_features, ))\n",
        "        history = model.fit(data_train, label_train, epochs = 50, batch_size = 32)\n",
        "        acc, prec, rec = predict_assess(model, data_test, label_test)\n",
        "        training_report(acc, prec, rec, threshold)\n",
        "        add_to_history(training_history, threshold, acc, prec, rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzrcwAEQdD9b"
      },
      "source": [
        "history_df = pd.DataFrame(training_history)\n",
        "history_df.to_csv('history.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}